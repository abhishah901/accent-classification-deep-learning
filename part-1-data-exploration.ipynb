{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10eb15a828bdd69d9870eccdbb12a1f9ad9d4b6d",
    "nbpresent": {
     "id": "42344751-df85-4fa9-af08-b4bf50b41e05"
    }
   },
   "source": [
    "# Part 1 - Data Exploration \n",
    "Eu Jin Lok\n",
    "<br>Kernel post for __[Speech Accent Archive](https://www.kaggle.com/rtatman/speech-accent-archive)__ on Kaggle\n",
    "<br>2 December 2019\n",
    "\n",
    "\n",
    "# Understanding the data and setting an objective\n",
    "\n",
    "\n",
    "In this notebook we will go into the details of how to explore audio data and converge on an objective, an objective which will most likely involve some kind of **deep learning**, because its awesome. If I do write a blog post about this, I will update this kernel. But for now, just the Jupyter notebook as a kernel, and my very first one!\n",
    "\n",
    "Before we begin, I just wanted to say that my first real heavy involvement in audio was back in March 2018 whilst doing the Audio competition on __[kaggle](https://www.kaggle.com/c/freesound-audio-tagging)__, Thanks to that competition and the awesome community support, I had learnt alot and so I wanted to contribute back to the community in the same way. So without further ado, lets begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "6ae51eccaaede3c8e466ef2445cfc73d522b4769",
    "nbpresent": {
     "id": "6b931974-2fc8-4fdc-9f32-a93d21ec08ef"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5dae6d645ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipd\u001b[0m  \u001b[0;31m# To play sound in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import pandas as pd       \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8074c219a8971892cd7c7d3567a802a44750c8c1"
   },
   "source": [
    "------------------------------\n",
    "After loading the libraries and setting our directory path, lets check out the meta datafile to see what we're dealing with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cdee6c3a7618c1e8094ace6f02e1e82597d4cf3"
   },
   "outputs": [],
   "source": [
    "#load the data \n",
    "df = pd.read_csv(\"speakers_all.csv\", header=0)\n",
    "\n",
    "# Check the data\n",
    "print(df.shape, 'is the shape of the dataset') \n",
    "print('------------------------') \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82cd408205db4c2cb080bee715c8ac164d561775"
   },
   "source": [
    "------------------------------\n",
    "I noticed some strange empty columns in the last 3 columns of the dataset. Lets clean it up and run some more stats and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59faa6b7798fd37e4eec47e068388497dfeb33d7"
   },
   "outputs": [],
   "source": [
    "df.drop(df.columns[9:12],axis = 1, inplace = True)\n",
    "print(df.columns)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f694e9e6ef817442d0b7a7311825aed39a4e29f2"
   },
   "source": [
    "------------------------------\n",
    "Not sure what the differences are for age and age_onset but not important at this stage. Nothing really outstanding at the moment... lets soldier on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71f9c57cf380cc04123555a442804cf20c4a52cb"
   },
   "outputs": [],
   "source": [
    "# Very rough plot\n",
    "df['country'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "446f10814e168852306219509d627dd6503b3262"
   },
   "outputs": [],
   "source": [
    "# Ok so that plot wasn't very good for that category. Lets try another category... \n",
    "df['native_language'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9bb7e8b880ac3d111d55c900b773f0872cd6b5a7"
   },
   "outputs": [],
   "source": [
    "# That's lots of categories too! Ok so maybe lets try a different way...\n",
    "df.groupby(\"native_language\")['age'].describe().sort_values(by=['count'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53e93beb6d91beb922b4d0bd17588d24d943a480"
   },
   "source": [
    "------------------------------\n",
    "Much better. No fancy visuals unfortunately but at least the insight comes through more in this format. The thing to note here is the lower number of Hindi speakers, which according to __[wikipedia](https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers)__ is the 4th most spoken language, with alot of caveats of course. Eitherways, this tables looks like a pretty good representative sample in general to me. Lets look at country of origin again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd3d2c3642bcc3f20d1433f1a36bb2262f9db9b4"
   },
   "outputs": [],
   "source": [
    "# Check country of origin again...\n",
    "df.groupby(\"country\")['age'].describe().sort_values(by=['count'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "599d101c49b31b539b871a89c48d4dfd098b5a03"
   },
   "source": [
    "------------------------------\n",
    "There's more native languages than there are countries which I suppose makes sense, although a hypothesis withstanding. A sankey type plot here would be interesting and very apprpriate to visualise this relationship, but lets park it for now as a seperate task. Right now, lets continue on with our main objective..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1be26d36582cb3a29069238bdaf881e4a7338200"
   },
   "outputs": [],
   "source": [
    "# Create DTM of counts \n",
    "df.groupby(\"sex\")['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12431b55c80ba28ec884d833d9a20f1081035809"
   },
   "source": [
    "------------------------------\n",
    "hmmm... must be a typo. Lets notify @Rachel Tatman about this observation... continue on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897a3f79f78ead895bc2389b5b25413ba28d7445"
   },
   "outputs": [],
   "source": [
    "# birthplace\n",
    "df.groupby(\"birthplace\")['age'].describe().sort_values(by=['count'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c5e1e247ab1a445f3b562f207fac13d7f4ba01a"
   },
   "source": [
    "------------------------------\n",
    "Birthplace is a very sparce datapoint with 1290 unique categories with very few observations in each one. Again could be interesting to see the patterns of Birthplace and Country relationship. Either a Network analysis or a Sankey plot may shed some light on whether all the Seoul birthplace observation equates to country. Ie. Could they be South Koreans living else where such as China or USA? \n",
    "\n",
    "Eithercase, park for a seperate mini project. Lets look at the file_missing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e792051b9ddc6599b08699a4a788df5ea1237ece"
   },
   "outputs": [],
   "source": [
    "# file_missing\n",
    "df.groupby(\"file_missing?\")['age'].describe().sort_values(by=['count'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9721faf4b4d647469e1f8ca074e1a9ef94357dc9"
   },
   "source": [
    "------------------------------\n",
    "2140 files with 32 missing. What does this actually mean? I read the overview page and there's no mention of this. So, lets go see it for ourselves... by counting the number of audio files we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d8e6b9517c7c92fb298121ee56872ed3d4ae943"
   },
   "outputs": [],
   "source": [
    "# Count the total audio files given\n",
    "print (len([name for name in os.listdir('../input/recordings/recordings') if os.path.isfile(os.path.join('../input/recordings/recordings', name))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ac6ac010311e47f8e5579e0ea6944537949bf84"
   },
   "source": [
    "------------------------------\n",
    "huh? 2138.... We have 2 missing audio files. Well, lets keep that in mind for now. We'll eventually find out which one's we're missing, and is really inconsequential either way given its just 2 files. Let continue on to the last column, the filename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad2802ea6e0886d3632d973037a3ccf35d13a8d4"
   },
   "outputs": [],
   "source": [
    "# filename column. This time we just print out the first 10 records. \n",
    "df.groupby(\"filename\")['age'].describe().sort_values(by=['count'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7031c4df1e9e0010d93213252033c0ec77928880"
   },
   "source": [
    "------------------------------\n",
    "Wait, there's some files that have the same filename. On closer inspection however, I suspect these filenames also have missing audio files. In which case it is ok. I have a suspicion that these dupe filenames also have missing audio files. So, lets have a look at doing a cross-tab of the 'filename' and 'file_missing?' column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180cb2449a02a0e66da7dbddf79c0b82ff2295f7"
   },
   "outputs": [],
   "source": [
    "# Cross-tab. Again, just print the first 10 record \n",
    "df.groupby(\"filename\")['file_missing?'].describe().sort_values(by=['count'],ascending=False).head(10)\n",
    "# pd.crosstab(df['filename'],df['file_missing?']) as an alternative method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0507bda07cd07c5a3da6ce6ee6e7c80b1ed4c104"
   },
   "source": [
    "--------------------------------------\n",
    "Ok so our suspicion is right, the filename with duplicate names have all missing audio files. Perfect! Everything checks out. We can go ahead a read in the audio files, and listen in to a few. We'll look at 'arikaans1' and 'mandarin46' since its on our periperal vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8ad9ba7e0be7ed5cccdedc20e4ab6dd4d43491c"
   },
   "outputs": [],
   "source": [
    "# Play afrikaans1\n",
    "fname1 = 'recordings/recordings/' + 'afrikaans1.mp3'\n",
    "ipd.Audio(fname1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfdaa4c68b91668dd4fb253b040983c83bab3b1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Play mandarin46\n",
    "fname2 = 'recordings/recordings/' + 'mandarin46.mp3'\n",
    "ipd.Audio(fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3a9b316d5a5fc1cd705ebeebc4a68359531319b"
   },
   "outputs": [],
   "source": [
    "# lets have a listen to a male voice. \n",
    "print(df.groupby(\"filename\")['sex'].describe().head(10))\n",
    "fname3 = 'recordings/recordings/' + 'agni1.mp3'   \n",
    "ipd.Audio(fname3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf0ce41307db2d72f57565e073ec2e854b385580"
   },
   "source": [
    "------------------------------\n",
    "Ok, so we've come to a point where we need to make a decision now. There's a few objectives worth pursuing on top of my head and they are: \n",
    "- building a gender predictor from voice\n",
    "- building an accent predictor by Country from voice (or Birthplace)\n",
    "\n",
    "All we could build all 2 applications above, starting from the easiest first being the gender predictor. The gender predictor will serve as our prototype and once we've built it, we'll expand to Country, and then maybe by Birthplace. I'm not even sure if Birthplace is viable objective but lets re-evaluate when we circle back to this. For now, **lets run with Gender first**. Also note that we don't have to limit ourselves with supervised modelling. There's many more we can do: \n",
    "- Audio fingerprinting \n",
    "- Emotion analysis (Text and Voice)\n",
    "- Speed, inflection etc etc\n",
    "- Others \n",
    "\n",
    "There's alot you can do with audio, but we'll look at these at a later stage. Meantime, the show must go on, and we will stick to our simple objective. Lets now run a few more examples of male and female audio files. This time, I want to hear the US Southern Accent. Cause I've always liked that accent and find it fascinating. =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18142b27ff9a08dccafa14b4fdf5b65b6898d5bb"
   },
   "outputs": [],
   "source": [
    "print(df[df['birthplace'].str.contains(\"kentucky\",na=False)])\n",
    "fname4 = 'recordings/recordings/' + 'english385.mp3'   \n",
    "ipd.Audio(fname4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b175be9d122fa4d18f0711db2f8b5347af7c7e6"
   },
   "outputs": [],
   "source": [
    "fname5 = 'recordings/recordings/' + 'english462.mp3'   \n",
    "ipd.Audio(fname5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6b3db43c66b8f815d57ed12a041b47c4a1af5bd"
   },
   "source": [
    "------------------------------\n",
    "The male version which is filename 'english462' doesn't have a strong Southern accent. And there's some distrotion of the audio at the start. Could pose a problem for our accent predictor by Birthplace, but nothing to worry about for Gender. Looking at the previous tables and plots, seems like there's some potential age correlation here. So lets hear one final one! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d61b585a3d08af1c0bc4cbe5dc36aea2a8449429"
   },
   "outputs": [],
   "source": [
    "fname6 = 'recordings/recordings/' + 'english381.mp3'   # An older male \n",
    "ipd.Audio(fname6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "359caf168990a811bf61a4b023961cf5c4ca026e"
   },
   "source": [
    "------------------------------\n",
    "Ok so I'll end this kernel here now, and we'll go ahead with creating a gender predictor as our first mini-objective, with the ultimate objective being to create an accent predictor. The next logical step after this is to analyse the audio files itself and extract features from it, which we'll do in the Part 2 of this series, coming soon in the next 2 to 3 weeks hopefully!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
