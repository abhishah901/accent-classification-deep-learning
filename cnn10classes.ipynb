{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X_all.npy')\n",
    "y = np.load('y_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X_train,y_train):  \n",
    "        self.dataset = X_train,y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'mfcc': X_train[idx], 'labels': y_train[idx]}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=AudioDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-6.05600928e+02, -4.22348209e+02, -1.95625449e+02, ...,\n",
       "          -3.01460864e+02, -1.37774933e+02, -6.93089500e+01],\n",
       "         [ 0.00000000e+00,  8.58180408e+01,  1.25907576e+02, ...,\n",
       "           7.54483118e+01,  7.19054112e+01,  7.79408023e+01],\n",
       "         [ 0.00000000e+00, -4.74510561e+01, -8.25658517e+01, ...,\n",
       "          -5.04117029e+01, -7.51347117e+01, -6.79016794e+01],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  5.24027526e+00,  6.81130687e+00, ...,\n",
       "           1.72358063e+01,  3.48511555e+01,  2.30152058e+01],\n",
       "         [ 0.00000000e+00, -1.27973494e+01, -1.74476597e+01, ...,\n",
       "           7.74626281e+00,  3.96455085e+00, -2.60227025e+00],\n",
       "         [ 0.00000000e+00,  2.37430803e-01, -6.23233646e+00, ...,\n",
       "          -1.57488092e-01, -1.09011070e+01, -1.14507291e+01]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[-3.84946054e+02, -3.67319455e+02, -3.46870910e+02, ...,\n",
       "          -3.39418901e+02, -1.69588258e+02, -1.01037406e+02],\n",
       "         [ 5.64784626e+01,  5.15286393e+01,  2.33832180e+01, ...,\n",
       "           3.50782513e+01,  3.40858243e+01,  2.86721433e+01],\n",
       "         [-2.44106774e+01, -2.07003236e+01, -4.23578179e+01, ...,\n",
       "          -4.40003188e+01, -7.71903815e+01, -6.69975796e+01],\n",
       "         ...,\n",
       "         [-1.73053094e+00, -4.12083927e-01,  4.00424780e+00, ...,\n",
       "          -5.64462025e+00, -1.21016784e+01, -1.13899059e+01],\n",
       "         [ 1.24008633e+00, -1.20129875e+00, -7.28585013e+00, ...,\n",
       "          -6.83365081e+00, -1.16789502e+01, -7.49812739e+00],\n",
       "         [ 4.60394967e-01,  1.90669121e+00, -7.93878476e+00, ...,\n",
       "          -1.14895079e+00, -6.73370299e+00, -1.28043571e+01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]]),\n",
       " array([9, 9, 9, ..., 3, 9, 9]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)        #Batch normalization\n",
    "        self.relu = nn.ReLU()                 #RELU Activation\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)   #Maxpooling reduces the size by kernel size. 64/2 = 32\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)    #Size now is 32/2 = 16\n",
    "        \n",
    "        #Flatten the feature maps. You have 32 feature mapsfrom cnn2. Each of the feature is of size 16x16 --> 32*16*16 = 8192\n",
    "        self.fc1 = nn.Linear(in_features=3360, out_features=4000)   #Flattened image is fed into linear NN and reduced to half size\n",
    "        self.droput = nn.Dropout(p=0.5)                    #Dropout used to reduce overfitting\n",
    "        self.fc2 = nn.Linear(in_features=4000, out_features=2000)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(in_features=2000, out_features=500)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc4 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc5 = nn.Linear(in_features=50, out_features=10)    #Since there were so many features, I decided to use 45 layers to get output layers. You can increase the kernels in Maxpooling to reduce image further and reduce number of hidden linear layers.\n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #Flattening is done here with .view() -> (batch_size, 32*16*16) = (100, 8192)\n",
    "        out = out.view(-1,3360)   #-1 will automatically update the batchsize as 100; 8192 flattens 32,16,16\n",
    "        #Then we forward through our fully connected layer \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()    \n",
    "loss_fn = nn.CrossEntropyLoss()        \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 1/150, Training Loss: 2.357, Training Accuracy: 0.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 2/150, Training Loss: 2.282, Training Accuracy: 0.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 3/150, Training Loss: 2.301, Training Accuracy: 0.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 4/150, Training Loss: 2.247, Training Accuracy: 0.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 5/150, Training Loss: 2.163, Training Accuracy: 50.000\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 6/150, Training Loss: 2.089, Training Accuracy: 100.000\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 7/150, Training Loss: 2.145, Training Accuracy: 50.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 8/150, Training Loss: 1.913, Training Accuracy: 100.000\n",
      "inputs tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n",
      "Epoch 9/150, Training Loss: 1.877, Training Accuracy: 100.000\n",
      "inputs tensor([[[[-6.0560e+02, -4.2235e+02, -1.9563e+02,  ..., -3.0146e+02,\n",
      "           -1.3777e+02, -6.9309e+01],\n",
      "          [ 0.0000e+00,  8.5818e+01,  1.2591e+02,  ...,  7.5448e+01,\n",
      "            7.1905e+01,  7.7941e+01],\n",
      "          [ 0.0000e+00, -4.7451e+01, -8.2566e+01,  ..., -5.0412e+01,\n",
      "           -7.5135e+01, -6.7902e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  5.2403e+00,  6.8113e+00,  ...,  1.7236e+01,\n",
      "            3.4851e+01,  2.3015e+01],\n",
      "          [ 0.0000e+00, -1.2797e+01, -1.7448e+01,  ...,  7.7463e+00,\n",
      "            3.9646e+00, -2.6023e+00],\n",
      "          [ 0.0000e+00,  2.3743e-01, -6.2323e+00,  ..., -1.5749e-01,\n",
      "           -1.0901e+01, -1.1451e+01]]]]) torch.Size([1, 1, 20, 85])\n",
      "labels tensor([9]) tensor([9], dtype=torch.int32)\n",
      "outputs torch.Size([1, 10]) label torch.Size([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8c82a9708a59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0miter_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# Accumulate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# Update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training the CNN\n",
    "\n",
    "import time\n",
    "\n",
    "num_epochs = 150\n",
    "\n",
    "#Define the lists to store the results of loss and accuracy\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#Training\n",
    "for epoch in range(num_epochs): \n",
    "    #Reset these below variables to 0 at the begining of every epoch\n",
    "    start = time.time()\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    iter_loss = 0.0\n",
    "    \n",
    "    model.train()                   # Put the network into training mode\n",
    "    \n",
    "    for i, data in enumerate(train_load):\n",
    "        \n",
    "        # Convert torch tensor to Variable\n",
    "        \n",
    "        \n",
    "        inputs = data['mfcc']\n",
    "        inputs = torch.FloatTensor(np.expand_dims(inputs,axis=1))\n",
    "        print(\"inputs\",inputs,inputs.shape)\n",
    "        \n",
    "        labels = data['labels']\n",
    "        labels = labels.long()\n",
    "        print(\"labels\",labels,data['labels'])\n",
    "\n",
    "\n",
    "        #print(\"labels\",labels)\n",
    "        # If we have GPU, shift the data to GPU\n",
    "        CUDA = torch.cuda.is_available()\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()            # Clear off the gradient in (w = w - gradient)\n",
    "        outputs = model(inputs) \n",
    "        print(\"outputs\",outputs.shape,\"label\",labels.shape)\n",
    "        loss = loss_fn(outputs, labels)  \n",
    "        iter_loss += loss.item()       # Accumulate the loss\n",
    "        loss.backward()                 # Backpropagation \n",
    "        optimizer.step()                # Update the weights\n",
    "\n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "\n",
    "        # Record the training loss\n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(dataset)))\n",
    "\n",
    "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}'\n",
    "            .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1]))\n",
    "\n",
    "    #Testing\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "#     model.eval()                    # Put the network into evaluation mode\n",
    "    \n",
    "#     for i, (inputs, labels) in enumerate(test_load):\n",
    "        \n",
    "#         # Convert torch tensor to Variable\n",
    "#         inputs = Variable(inputs)\n",
    "#         labels = Variable(labels)\n",
    "        \n",
    "#         CUDA = torch.cuda.is_available()\n",
    "#         if CUDA:\n",
    "#             inputs = inputs.cuda()\n",
    "#             labels = labels.cuda()\n",
    "        \n",
    "#         outputs = model(inputs)     \n",
    "#         loss = loss_fn(outputs, labels) # Calculate the loss\n",
    "#         loss += loss.data[0]\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         correct += (predicted == labels).sum()\n",
    "        \n",
    "#         iterations += 1\n",
    "\n",
    "#     # Record the Testing loss\n",
    "#     test_loss.append(loss/iterations)\n",
    "#     # Record the Testing accuracy\n",
    "#     test_accuracy.append((100 * correct / len(test_dataset)))\n",
    "#     stop = time.time()\n",
    "    \n",
    "#     print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Testing Loss: {:.3f}, Testing Acc: {:.3f}, Time: {}s'\n",
    "#            .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], test_loss[-1], test_accuracy[-1], stop-start))\n",
    "\n",
    "      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
