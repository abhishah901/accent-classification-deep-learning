{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dim = 999\n",
    "maxlen = 100\n",
    "batch_size = 100\n",
    "nb_filter = 64\n",
    "filter_length_1 = 50\n",
    "filter_length_2 = 25\n",
    "hidden_dims = 250\n",
    "nb_epoch = 8\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X_all.npy')\n",
    "y = np.load('y_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710 428\n",
      "1710 428\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xts = X_train.shape\n",
    "# X_train = np.reshape(X_train, (xts[0], xts[1],xts[2],1))\n",
    "# xtss = X_test.shape\n",
    "# X_test = np.reshape(X_test, (xtss[0], xtss[1],xts[2],1))\n",
    "# yts = y_train.shape\n",
    "# y_train = np.reshape(y_train, (yts[0], 1))\n",
    "# ytss = y_test.shape\n",
    "# y_test = np.reshape(y_test, (ytss[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 85)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710 428\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(20, 85), activation=\"relu\", filters=64, kernel_size=3, padding=\"valid\")`\n",
      "  \n",
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=64, kernel_size=25, padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=64, kernel_size=25, padding=\"same\")`\n",
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\karth\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1710 samples, validate on 428 samples\n",
      "Epoch 1/8\n",
      "1710/1710 [==============================] - 4s 2ms/step - loss: 0.3088 - accuracy: 0.8944 - val_loss: 0.3267 - val_accuracy: 0.9037\n",
      "Epoch 2/8\n",
      "1710/1710 [==============================] - 1s 598us/step - loss: 0.2745 - accuracy: 0.8989 - val_loss: 0.3130 - val_accuracy: 0.9037\n",
      "Epoch 3/8\n",
      "1710/1710 [==============================] - 1s 623us/step - loss: 0.2686 - accuracy: 0.9006 - val_loss: 0.2869 - val_accuracy: 0.9037\n",
      "Epoch 4/8\n",
      "1710/1710 [==============================] - 1s 577us/step - loss: 0.2688 - accuracy: 0.8992 - val_loss: 0.2771 - val_accuracy: 0.9037\n",
      "Epoch 5/8\n",
      "1710/1710 [==============================] - 1s 640us/step - loss: 0.2665 - accuracy: 0.8998 - val_loss: 0.2619 - val_accuracy: 0.9028\n",
      "Epoch 6/8\n",
      "1710/1710 [==============================] - 1s 589us/step - loss: 0.2672 - accuracy: 0.8987 - val_loss: 0.2617 - val_accuracy: 0.9037\n",
      "Epoch 7/8\n",
      "1710/1710 [==============================] - 1s 577us/step - loss: 0.2681 - accuracy: 0.9019 - val_loss: 0.2455 - val_accuracy: 0.9033\n",
      "Epoch 8/8\n",
      "1710/1710 [==============================] - 1s 625us/step - loss: 0.2641 - accuracy: 0.8980 - val_loss: 0.2459 - val_accuracy: 0.9028\n",
      "428/428 [==============================] - 0s 256us/step\n",
      "[0.24591391860881698, 0.9028037190437317]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=64,filter_length=3,\n",
    "                        input_shape=(20,85),\n",
    "                        \n",
    "                        border_mode='valid',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "# we use standard max pooling (halving the output of the previous layer):\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length_2,\n",
    "                        border_mode='same',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length_2,\n",
    "                        border_mode='same',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "# We flatten the output of the conv layer,\n",
    "# so that we can add a vanilla dense layer:\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "# model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "               metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,  verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test,  verbose=1)\n",
    "\n",
    "print(\"score\",score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
