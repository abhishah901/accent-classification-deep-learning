{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/run/media/abhi/0B8B16F90B8B16F9/git-repos/accent-classification-deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('recordings/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_delta</th>\n",
       "      <th>mfcc_std</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afrikaans1.mp3</td>\n",
       "      <td>[-286.9996, 101.00333, 16.233343, 38.55001, 13...</td>\n",
       "      <td>[-0.073486894, -0.049424816, 0.02006524, 0.014...</td>\n",
       "      <td>[82.88693, 52.9065, 28.253935, 25.437798, 16.5...</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afrikaans2.mp3</td>\n",
       "      <td>[-253.3392, 95.28, 6.2911716, 40.50932, 24.627...</td>\n",
       "      <td>[0.11593776, 0.10964334, 0.04565616, 0.0341781...</td>\n",
       "      <td>[95.728546, 63.766106, 30.927711, 23.096176, 2...</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afrikaans3.mp3</td>\n",
       "      <td>[-304.96454, 114.367935, 3.0879085, 41.2587, 1...</td>\n",
       "      <td>[0.023992734, -0.024612058, 0.0011315645, 0.01...</td>\n",
       "      <td>[86.821434, 54.26066, 32.013527, 28.682323, 27...</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afrikaans4.mp3</td>\n",
       "      <td>[-255.06078, 119.76244, 9.096731, 49.751278, 1...</td>\n",
       "      <td>[0.1938841, 0.062215883, 0.018687284, 0.035407...</td>\n",
       "      <td>[78.09206, 58.238373, 25.920147, 28.550196, 25...</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrikaans5.mp3</td>\n",
       "      <td>[-330.7317, 106.468315, 15.5614195, 12.015123,...</td>\n",
       "      <td>[-0.0027107962, -0.019274525, -0.020551698, -0...</td>\n",
       "      <td>[85.777336, 70.045845, 25.799347, 29.101786, 2...</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               mfcc  \\\n",
       "0  afrikaans1.mp3  [-286.9996, 101.00333, 16.233343, 38.55001, 13...   \n",
       "1  afrikaans2.mp3  [-253.3392, 95.28, 6.2911716, 40.50932, 24.627...   \n",
       "2  afrikaans3.mp3  [-304.96454, 114.367935, 3.0879085, 41.2587, 1...   \n",
       "3  afrikaans4.mp3  [-255.06078, 119.76244, 9.096731, 49.751278, 1...   \n",
       "4  afrikaans5.mp3  [-330.7317, 106.468315, 15.5614195, 12.015123,...   \n",
       "\n",
       "                                          mfcc_delta  \\\n",
       "0  [-0.073486894, -0.049424816, 0.02006524, 0.014...   \n",
       "1  [0.11593776, 0.10964334, 0.04565616, 0.0341781...   \n",
       "2  [0.023992734, -0.024612058, 0.0011315645, 0.01...   \n",
       "3  [0.1938841, 0.062215883, 0.018687284, 0.035407...   \n",
       "4  [-0.0027107962, -0.019274525, -0.020551698, -0...   \n",
       "\n",
       "                                            mfcc_std     accent  \n",
       "0  [82.88693, 52.9065, 28.253935, 25.437798, 16.5...  afrikaans  \n",
       "1  [95.728546, 63.766106, 30.927711, 23.096176, 2...  afrikaans  \n",
       "2  [86.821434, 54.26066, 32.013527, 28.682323, 27...  afrikaans  \n",
       "3  [78.09206, 58.238373, 25.920147, 28.550196, 25...  afrikaans  \n",
       "4  [85.777336, 70.045845, 25.799347, 29.101786, 2...  afrikaans  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english       579\n",
       "spanish       162\n",
       "arabic        102\n",
       "mandarin       65\n",
       "french         63\n",
       "korean         52\n",
       "russian        48\n",
       "portuguese     48\n",
       "dutch          47\n",
       "turkish        37\n",
       "Name: accent, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['accent'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = ['spanish','mandarin','arabic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_df = df[df['accent'].isin(trial)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_delta</th>\n",
       "      <th>mfcc_std</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arabic1.mp3</td>\n",
       "      <td>[-247.81822, 86.44767, 12.032201, 48.378105, 4...</td>\n",
       "      <td>[-0.04136087, -0.0059153144, 0.010516524, -0.0...</td>\n",
       "      <td>[48.531845, 32.1262, 20.30426, 18.17278, 12.51...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arabic10.mp3</td>\n",
       "      <td>[-339.0816, 95.899734, 9.910238, 21.570919, 23...</td>\n",
       "      <td>[-5.1055224e-05, -5.922301e-05, -2.4135676e-05...</td>\n",
       "      <td>[97.08705, 58.760323, 33.476955, 22.752375, 22...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arabic100.mp3</td>\n",
       "      <td>[-322.04126, 85.5467, 12.21659, 7.0353518, -10...</td>\n",
       "      <td>[-0.06968477, -0.027437836, -0.004780271, -0.0...</td>\n",
       "      <td>[76.34836, 57.511307, 26.010773, 23.924608, 17...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arabic101.mp3</td>\n",
       "      <td>[-318.56363, 83.090935, 5.342441, 39.01211, 6....</td>\n",
       "      <td>[0.054670453, 0.021878112, -0.004269967, -1.39...</td>\n",
       "      <td>[93.40922, 54.535133, 26.85341, 24.297579, 21....</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arabic102.mp3</td>\n",
       "      <td>[-251.829, 87.90869, 34.786392, 47.979828, 4.2...</td>\n",
       "      <td>[-0.08893812, -0.048280712, -0.024698531, -0.0...</td>\n",
       "      <td>[90.563324, 59.792763, 26.25485, 21.295261, 21...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               mfcc  \\\n",
       "36    arabic1.mp3  [-247.81822, 86.44767, 12.032201, 48.378105, 4...   \n",
       "37   arabic10.mp3  [-339.0816, 95.899734, 9.910238, 21.570919, 23...   \n",
       "38  arabic100.mp3  [-322.04126, 85.5467, 12.21659, 7.0353518, -10...   \n",
       "39  arabic101.mp3  [-318.56363, 83.090935, 5.342441, 39.01211, 6....   \n",
       "40  arabic102.mp3  [-251.829, 87.90869, 34.786392, 47.979828, 4.2...   \n",
       "\n",
       "                                           mfcc_delta  \\\n",
       "36  [-0.04136087, -0.0059153144, 0.010516524, -0.0...   \n",
       "37  [-5.1055224e-05, -5.922301e-05, -2.4135676e-05...   \n",
       "38  [-0.06968477, -0.027437836, -0.004780271, -0.0...   \n",
       "39  [0.054670453, 0.021878112, -0.004269967, -1.39...   \n",
       "40  [-0.08893812, -0.048280712, -0.024698531, -0.0...   \n",
       "\n",
       "                                             mfcc_std  accent  \n",
       "36  [48.531845, 32.1262, 20.30426, 18.17278, 12.51...  arabic  \n",
       "37  [97.08705, 58.760323, 33.476955, 22.752375, 22...  arabic  \n",
       "38  [76.34836, 57.511307, 26.010773, 23.924608, 17...  arabic  \n",
       "39  [93.40922, 54.535133, 26.85341, 24.297579, 21....  arabic  \n",
       "40  [90.563324, 59.792763, 26.25485, 21.295261, 21...  arabic  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_delta</th>\n",
       "      <th>mfcc_std</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arabic26.mp3</td>\n",
       "      <td>[-344.65906, 103.28302, -14.60107, 18.86604, -...</td>\n",
       "      <td>[1.6310839e-08, -8.1554195e-09, 7.135992e-09, ...</td>\n",
       "      <td>[98.716965, 44.788467, 34.90897, 30.455093, 22...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish25.mp3</td>\n",
       "      <td>[-324.95822, 103.578964, 7.4686775, 39.055206,...</td>\n",
       "      <td>[-0.18015285, -0.04311364, 0.018135171, -0.032...</td>\n",
       "      <td>[77.16646, 53.025833, 23.661644, 24.035664, 20...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arabic96.mp3</td>\n",
       "      <td>[-307.0369, 98.088104, -6.821254, 10.463601, 8...</td>\n",
       "      <td>[-0.034998953, -0.026296312, 0.01704629, 0.016...</td>\n",
       "      <td>[81.24166, 54.190506, 33.376736, 22.668365, 21...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish88.mp3</td>\n",
       "      <td>[-342.00122, 91.30479, -3.5629144, 29.186909, ...</td>\n",
       "      <td>[-0.07403751, -0.03679634, 0.00053725863, -0.0...</td>\n",
       "      <td>[125.2681, 62.07376, 28.875532, 30.912693, 27....</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish123.mp3</td>\n",
       "      <td>[-312.0809, 81.846664, -26.574839, 16.248684, ...</td>\n",
       "      <td>[-0.047235023, 0.0054397904, 0.030579984, -0.0...</td>\n",
       "      <td>[84.2598, 63.405018, 40.562294, 36.177715, 20....</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               mfcc  \\\n",
       "0    arabic26.mp3  [-344.65906, 103.28302, -14.60107, 18.86604, -...   \n",
       "1   spanish25.mp3  [-324.95822, 103.578964, 7.4686775, 39.055206,...   \n",
       "2    arabic96.mp3  [-307.0369, 98.088104, -6.821254, 10.463601, 8...   \n",
       "3   spanish88.mp3  [-342.00122, 91.30479, -3.5629144, 29.186909, ...   \n",
       "4  spanish123.mp3  [-312.0809, 81.846664, -26.574839, 16.248684, ...   \n",
       "\n",
       "                                          mfcc_delta  \\\n",
       "0  [1.6310839e-08, -8.1554195e-09, 7.135992e-09, ...   \n",
       "1  [-0.18015285, -0.04311364, 0.018135171, -0.032...   \n",
       "2  [-0.034998953, -0.026296312, 0.01704629, 0.016...   \n",
       "3  [-0.07403751, -0.03679634, 0.00053725863, -0.0...   \n",
       "4  [-0.047235023, 0.0054397904, 0.030579984, -0.0...   \n",
       "\n",
       "                                            mfcc_std   accent  \n",
       "0  [98.716965, 44.788467, 34.90897, 30.455093, 22...   arabic  \n",
       "1  [77.16646, 53.025833, 23.661644, 24.035664, 20...  spanish  \n",
       "2  [81.24166, 54.190506, 33.376736, 22.668365, 21...   arabic  \n",
       "3  [125.2681, 62.07376, 28.875532, 30.912693, 27....  spanish  \n",
       "4  [84.2598, 63.405018, 40.562294, 36.177715, 20....  spanish  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_one_mfcc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_one_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_one_mfcc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-5be56b1fc99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;31m# import sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;31m# import np_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m \u001b[0;31m# import Sequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# from tf.keras.optimizers import SGD\n",
    "import sklearn\n",
    " \n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import tf.keras.preprocessing.sequence # import sequence\n",
    "import tf.keras.utils.np_utils # import np_utils\n",
    "import tf.keras.models.Sequential # import Sequential\n",
    "import tf.keras.layers.core.Dense # import Dense, Dropout, Activation\n",
    "import tf.keras.layers.core.Dropout\n",
    "import tf.keras.layers.core.Activation\n",
    "import tf.keras.layers.recurrent.LSTM # import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_delta</th>\n",
       "      <th>mfcc_std</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arabic26.mp3</td>\n",
       "      <td>[-344.65906, 103.28302, -14.60107, 18.86604, -...</td>\n",
       "      <td>[1.6310839e-08, -8.1554195e-09, 7.135992e-09, ...</td>\n",
       "      <td>[98.716965, 44.788467, 34.90897, 30.455093, 22...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish25.mp3</td>\n",
       "      <td>[-324.95822, 103.578964, 7.4686775, 39.055206,...</td>\n",
       "      <td>[-0.18015285, -0.04311364, 0.018135171, -0.032...</td>\n",
       "      <td>[77.16646, 53.025833, 23.661644, 24.035664, 20...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arabic96.mp3</td>\n",
       "      <td>[-307.0369, 98.088104, -6.821254, 10.463601, 8...</td>\n",
       "      <td>[-0.034998953, -0.026296312, 0.01704629, 0.016...</td>\n",
       "      <td>[81.24166, 54.190506, 33.376736, 22.668365, 21...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish88.mp3</td>\n",
       "      <td>[-342.00122, 91.30479, -3.5629144, 29.186909, ...</td>\n",
       "      <td>[-0.07403751, -0.03679634, 0.00053725863, -0.0...</td>\n",
       "      <td>[125.2681, 62.07376, 28.875532, 30.912693, 27....</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish123.mp3</td>\n",
       "      <td>[-312.0809, 81.846664, -26.574839, 16.248684, ...</td>\n",
       "      <td>[-0.047235023, 0.0054397904, 0.030579984, -0.0...</td>\n",
       "      <td>[84.2598, 63.405018, 40.562294, 36.177715, 20....</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               mfcc  \\\n",
       "0    arabic26.mp3  [-344.65906, 103.28302, -14.60107, 18.86604, -...   \n",
       "1   spanish25.mp3  [-324.95822, 103.578964, 7.4686775, 39.055206,...   \n",
       "2    arabic96.mp3  [-307.0369, 98.088104, -6.821254, 10.463601, 8...   \n",
       "3   spanish88.mp3  [-342.00122, 91.30479, -3.5629144, 29.186909, ...   \n",
       "4  spanish123.mp3  [-312.0809, 81.846664, -26.574839, 16.248684, ...   \n",
       "\n",
       "                                          mfcc_delta  \\\n",
       "0  [1.6310839e-08, -8.1554195e-09, 7.135992e-09, ...   \n",
       "1  [-0.18015285, -0.04311364, 0.018135171, -0.032...   \n",
       "2  [-0.034998953, -0.026296312, 0.01704629, 0.016...   \n",
       "3  [-0.07403751, -0.03679634, 0.00053725863, -0.0...   \n",
       "4  [-0.047235023, 0.0054397904, 0.030579984, -0.0...   \n",
       "\n",
       "                                            mfcc_std   accent  \n",
       "0  [98.716965, 44.788467, 34.90897, 30.455093, 22...   arabic  \n",
       "1  [77.16646, 53.025833, 23.661644, 24.035664, 20...  spanish  \n",
       "2  [81.24166, 54.190506, 33.376736, 22.668365, 21...   arabic  \n",
       "3  [125.2681, 62.07376, 28.875532, 30.912693, 27....  spanish  \n",
       "4  [84.2598, 63.405018, 40.562294, 36.177715, 20....  spanish  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.accent = sub_df.accent.replace({'spanish':0,'mandarin':1,'arabic':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sub_df['mfcc'], dtype=object)\n",
    "y = np.array(sub_df['accent'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 329 into shape (329,20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-b3bcdf29d4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m329\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 329 into shape (329,20)"
     ]
    }
   ],
   "source": [
    "X.reshape(329,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 0, 2, 0, 2, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dim = 2999\n",
    "maxlen = 100\n",
    "batch_size = 30\n",
    "nb_filter = 64\n",
    "filter_length_1 = 50\n",
    "filter_length_2 = 25\n",
    "hidden_dims = 250\n",
    "nb_epoch = 8\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-33b33af99782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tf.keras.layers.core.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 train sequences\n",
      "50 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fca4c353e50>) with an unsupported type (<class 'tensorflow.python.keras.engine.sequential.Sequential'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2260\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2261\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ExpandDims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-ac7cdf6ce953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model.add(tf.keras.layers.LSTM(64, return_sequences=True, stateful=False,\n\u001b[1;32m      4\u001b[0m                batch_input_shape= (batch_size, 20)))\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m   \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2264\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         return expand_dims_eager_fallback(\n\u001b[0m\u001b[1;32m   2267\u001b[0m             input, axis, name=name, ctx=_ctx)\n\u001b[1;32m   2268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_eager_fallback\u001b[0;34m(input, axis, name, ctx)\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_dims_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2289\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2290\u001b[0m   \u001b[0m_attr_Tdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       ret.append(\n\u001b[0;32m--> 262\u001b[0;31m           ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    263\u001b[0m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[0;32m--> 261\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fca4c353e50>) with an unsupported type (<class 'tensorflow.python.keras.engine.sequential.Sequential'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model = tf.expand_dims(model, axis=-1)\n",
    "model.add(tf.keras.layers.LSTM(64, return_sequences=True, stateful=False,\n",
    "               batch_input_shape= (batch_size, 20)))\n",
    "model.add(tf.keras.layers.LSTM(64, return_sequences=True, stateful=False))\n",
    "model.add(tf.keras.layers.LSTM(64, stateful=False))\n",
    "\n",
    "# model.add(Conv2D(20,(5,5), input_shape = (30, 24, 48), activation = \"relu\", strides = 1, padding = \"valid\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))        \n",
    "# model.add(Conv2D(50, (5,5), use_bias = 50))    \n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(20, activation = \"relu\"))\n",
    "# model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
    "# model.add(LSTM(50, activation=\"relu\", return_sequences=True))\n",
    "\n",
    "\n",
    "\n",
    "# add dropout to control for overfitting\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "\n",
    "# squash output onto number of classes in probability space\n",
    "model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5, validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred=model.predict_classes(X_test, batch_size=batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-35fc9894a618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# we add a Convolution1D, which will learn nb_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# word group filters of size filter_length:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model.add(tf.keras.layers.Convolution1D(nb_filter=nb_filter,\n\u001b[0m\u001b[1;32m     11\u001b[0m                         \u001b[0mfilter_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_length_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "# model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(tf.keras.layers.Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length_1,\n",
    "                        input_shape=(test_dim, 13),\n",
    "                        border_mode='valid',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "# we use standard max pooling (halving the output of the previous layer):\n",
    "model.add(tf.keras.layers.normalization.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length_2,\n",
    "                        border_mode='same',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "\n",
    "model.add(tf.keras.layers.normalization.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(tf.keras.layers.Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length_2,\n",
    "                        border_mode='same',\n",
    "                        activation='relu'\n",
    "                        ))\n",
    "\n",
    "model.add(tf.keras.layers.normalization.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_length=2))\n",
    "\n",
    "# We flatten the output of the conv layer,\n",
    "# so that we can add a vanilla dense layer:\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "# model.add(Dense(hidden_dims))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop')\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,  verbose=1,\n",
    "          validation_data=(X_test, Y_test), show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-5b27f558cbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu',\n\u001b[1;32m      4\u001b[0m                  \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_last\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  input_shape=input_shape))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu',\n",
    "                 data_format=\"channels_last\",\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Stops training if accuracy does not change at least 0.005 over 10 epochs\n",
    "# es = EarlyStopping(monitor='acc', min_delta=.005, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# # # Creates log file for graphical interpretation using TensorBoard\n",
    "# # tb = TensorBoard(log_dir='../logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True,\n",
    "# #                  write_images=True, embeddings_freq=0, embeddings_layer_names=None,\n",
    "# #                  embeddings_metadata=None)\n",
    "\n",
    "# Image shifting\n",
    "# datagen = ImageDataGenerator(width_shift_range=0.05)\n",
    "\n",
    "# Fit model using ImageDataGenerator\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train) / 32\n",
    "                    , epochs=EPOCHS,\n",
    "                    callbacks=[es,tb], validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
